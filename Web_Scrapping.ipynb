{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web Scrapping.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPp4U4QU8zIFuK/c6IBKIXR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alvarorl231/ResearchMethods/blob/main/Web_Scrapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Scrapping"
      ],
      "metadata": {
        "id": "ToJhqa0jwy5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports, etc."
      ],
      "metadata": {
        "id": "bN_aB1XCwydV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install BeautifulSoup4\n",
        "!pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6rqbNGY33U6",
        "outputId": "2bdd39bc-3fcb-45df-ce21-38b079ab7caf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: BeautifulSoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6EYTiurz4BxE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Declaración de Variables"
      ],
      "metadata": {
        "id": "bHY6zqV3QW-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista que contendrá toda la información\n",
        "frases = []\n",
        "\n",
        "# Lista que almacenara el contenido sensible\n",
        "sensitive=[]\n",
        "\n",
        "# Lista que almacenara el contenido NO sensible\n",
        "nonsensitive=[]\n",
        "\n",
        "# Keywords\n",
        "keywords = ['ametralladora', 'arma', 'ataque', 'batallón', 'bomba', \n",
        "             'capitán', 'comandante', 'compañía', 'disparo', 'herido',\n",
        "             'muerto', 'munición', 'oficial', 'tiro', 'tiroteo']\n"
      ],
      "metadata": {
        "id": "Kl-9ZaUe02yZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Request y Extracción de información "
      ],
      "metadata": {
        "id": "rYOwxpsTwiDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Periódico: [ElDiario](https://www.eldiario.es/internacional)"
      ],
      "metadata": {
        "id": "xt6iwj2r1jW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eldiario_url = \"https://www.eldiario.es/internacional\"\n",
        "\n",
        "eldiario_result = requests.get(eldiario_url)\n",
        "\n",
        "doc = BeautifulSoup(eldiario_result.text, \"html.parser\")\n",
        "\n",
        "eldiario_html_tags = doc.find_all(\"h2\")\n",
        "\n",
        "\n",
        "for text in eldiario_html_tags:\n",
        "    text = str(text.string)\n",
        "    frases.append(text)"
      ],
      "metadata": {
        "id": "AbhEreUy5g4q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Periódico: [El País](https://elpais.com/ultimas-noticias/)"
      ],
      "metadata": {
        "id": "UjHUTM_z1_ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "elpais_url = \"https://elpais.com/ultimas-noticias/\"\n",
        "\n",
        "elpais_result = requests.get(elpais_url)\n",
        "\n",
        "doc = BeautifulSoup(elpais_result.text, \"html.parser\")\n",
        "\n",
        "elpais_html_tags = doc.find_all(\"h2\")\n",
        "\n",
        "for text in elpais_html_tags:\n",
        "    text = str(text.string)\n",
        "    frases.append(text)"
      ],
      "metadata": {
        "id": "pb6QLRRu0rra"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Periódico: [El Mundo](https://www.elmundo.es/ultimas-noticias.html)"
      ],
      "metadata": {
        "id": "u2-SqDdG2sjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "elmundo_url = \"https://www.elmundo.es/ultimas-noticias.html\"\n",
        "\n",
        "elmundo_result = requests.get(elmundo_url)\n",
        "\n",
        "doc = BeautifulSoup(elmundo_result.text, \"html.parser\")\n",
        "\n",
        "elmundo_html_tags = doc.find_all(\"h2\")\n",
        "\n",
        "for text in elmundo_html_tags:\n",
        "    text = str(text.string)\n",
        "    frases.append(text)"
      ],
      "metadata": {
        "id": "lfadMEfG2gni"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Periódico: [La Razón](https://www.larazon.es/internacional/)"
      ],
      "metadata": {
        "id": "tBFr1bsfDIOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este periódico tiene la propiedad de que muestran las noticias en webs con urls del estilo:\n",
        "```\n",
        "https://www.larazon.es/internacional/\n",
        "https://www.larazon.es/internacional/1/\n",
        "https://www.larazon.es/internacional/2/\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        "https://www.larazon.es/internacional/n/\n",
        "```\n",
        "Esto facilita mucho el scrapping, ya que al conseguir extraer los datos de una página, para las n siguientes solo debes aplicar un bucle."
      ],
      "metadata": {
        "id": "B4Ys7F8jGtvE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "De ese modo, la función `get_larazon_tags` nos ayudara a agilizar el proceso y a obtener una mayor limpieza en el código"
      ],
      "metadata": {
        "id": "2LFeX3ouHam-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_larazon_tags (url):\n",
        "\n",
        " result = requests.get(url)\n",
        "\n",
        " doc = BeautifulSoup(result.text, \"html.parser\")\n",
        "\n",
        " html_tags = doc.find_all(\"span\")\n",
        " \n",
        " return html_tags"
      ],
      "metadata": {
        "id": "3Z7RRv_tGta8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este bucle tiene una cierta característica por esto: \n",
        "```python\n",
        "for text in tags:\n",
        "    text = str(text.string)\n",
        "    if len(text) > 15:\n",
        "     frases.append(text)\n",
        "```\n",
        "En concreto el casting `text = str(text.string)` y la condición `if len(text) > 15:`, utilizados para obtener información útil y deshacernos de cadenas sin utilidad como: `None, Cerrar sesión, Submenú, etc..` "
      ],
      "metadata": {
        "id": "cHPVxtxMHnUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,2382):\n",
        "  if i == 1:\n",
        "   larazon_url = \"https://www.larazon.es/internacional/\"\n",
        "   tags = get_larazon_tags(larazon_url)\n",
        "   for text in tags:\n",
        "    text = str(text.string)\n",
        "    if len(text) > 15:\n",
        "     frases.append(text)\n",
        "  else:\n",
        "   new_url = f\"https://www.larazon.es/internacional/{i}/\"\n",
        "   tags = get_larazon_tags(new_url)\n",
        "   for text in tags:\n",
        "    text = str(text.string)\n",
        "    if len(text) > 15:\n",
        "     frases.append(text)"
      ],
      "metadata": {
        "id": "wIS-351Z4P-_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez realizado esto, con este simple `for`, almacenamos la información obtenidos"
      ],
      "metadata": {
        "id": "tj9cgKOOxUJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selección de palabras sensibles"
      ],
      "metadata": {
        "id": "BcqPlBp0J_oW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tras esto limpiamos la lista de frases obtenida anteriormente y la empleamos para buscar el contenido sensible"
      ],
      "metadata": {
        "id": "oECnzmqLPHlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ahora vamos eliminar duplicados con set()\n",
        "frases = list(set(frases))\n",
        "\n",
        "# Por cada keyword busca en todos los elementos de la lista frases, si se da esta condición, se almacena.\n",
        "for i in keywords:\n",
        "  for j in range(len(frases)):\n",
        "    if i in frases[j]:\n",
        "      sensitive.append(frases[j])\n",
        "\n",
        "sensitive = list(set(sensitive))"
      ],
      "metadata": {
        "id": "6yynmaJOKDnB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonsensitive = [i for i in frases if i not in sensitive]\n",
        "nonsensitive = list(set(nonsensitive))"
      ],
      "metadata": {
        "id": "pwaynRThgemI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Almacenar los datos en archivos `.csv`"
      ],
      "metadata": {
        "id": "mHwdctSnwbYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Todos los títulos de las noticias\n",
        "df = pd.DataFrame(frases)\n",
        "df.to_csv(\"frases.csv\", index=False)\n",
        "\n",
        "# Todos los títulos SENSIBLES\n",
        "df = pd.DataFrame(sensitive)\n",
        "df.to_csv(\"sensitive_frases.csv\", index=False)\n",
        "\n",
        "# Todos los títulos NO SENSIBLES\n",
        "\n",
        "df = pd.DataFrame(nonsensitive)\n",
        "df.to_csv(\"nonsensitive_frases.csv\", index=False)"
      ],
      "metadata": {
        "id": "20smqmz0vnQ2"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}